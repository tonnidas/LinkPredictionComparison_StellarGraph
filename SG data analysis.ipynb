{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3216395e",
   "metadata": {},
   "source": [
    "* Analyzing difference between stellargraph datasets and ARGA repository datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e786e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify that we're using the correct version of StellarGraph for this notebook\n",
    "import stellargraph as sg\n",
    "\n",
    "try:\n",
    "    sg.utils.validate_notebook_version(\"1.2.1\")\n",
    "except AttributeError:\n",
    "    raise ValueError(\n",
    "        f\"This notebook requires StellarGraph version 1.2.1, but a different version {sg.__version__} is installed.  Please see <https://github.com/stellargraph/stellargraph/issues/1172>.\"\n",
    "    ) from None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2329c2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from math import isclose\n",
    "from sklearn.decomposition import PCA\n",
    "import os\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from stellargraph import StellarGraph, datasets\n",
    "from stellargraph.data import EdgeSplitter\n",
    "from collections import Counter\n",
    "import multiprocessing\n",
    "from IPython.display import display, HTML\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import sparse\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7dfca33e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "The Cora dataset consists of 2708 scientific publications classified into one of seven classes. The citation network consists of 5429 links. Each publication in the dataset is described by a 0/1-valued word vector indicating the absence/presence of the corresponding word from the dictionary. The dictionary consists of 1433 unique words."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loading dataset from stellargraph library\n",
    "dataset = datasets.Cora()\n",
    "display(HTML(dataset.description))\n",
    "# graph, _ = dataset.load(largest_connected_component_only=True, str_node_ids=True)\n",
    "graph, _ = dataset.load(largest_connected_component_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e605a816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StellarGraph: Undirected multigraph\n",
      " Nodes: 2485, Edges: 5209\n",
      "\n",
      " Node types:\n",
      "  paper: [2485]\n",
      "    Features: float32 vector, length 1433\n",
      "    Edge types: paper-cites->paper\n",
      "\n",
      " Edge types:\n",
      "    paper-cites->paper: [5209]\n",
      "        Weights: all 1 (default)\n",
      "        Features: none\n"
     ]
    }
   ],
   "source": [
    "print(graph.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4cad77d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = graph.node_features(nodes=None)\n",
    "# features = sparse.csr_matrix(features)\n",
    "features = sparse.csr_matrix(features)\n",
    "adj = graph.to_adjacency_matrix(nodes=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8ba32879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Tonni\n",
    "\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from collections import defaultdict\n",
    "from scipy import sparse\n",
    "\n",
    "\n",
    "def getNHopNeighbors(node, hop, adjList): # It is simply a bfs till nhop, not on whole graph\n",
    "    neighborsTillHop, n_neighbors = set(), {node}\n",
    "\n",
    "    for i in range(hop):\n",
    "        temp = set()\n",
    "\n",
    "        for curNode in n_neighbors:\n",
    "            if curNode in adjList:\n",
    "                temp = temp.union(set(adjList[curNode]))\n",
    "        \n",
    "        neighborsTillHop = neighborsTillHop.union(temp)\n",
    "        n_neighbors = temp\n",
    "    \n",
    "    return neighborsTillHop\n",
    "\n",
    "# converts from adjacency matrix to adjacency list\n",
    "def convert(numNodes, adj):\n",
    "    adj = adj.todense()\n",
    "    adjList = defaultdict(list) # Type: Default value is empty list\n",
    "    for i in range(numNodes):\n",
    "        for j in range(numNodes):\n",
    "                if adj[i,j] == 1:\n",
    "                    adjList[i].append(j)\n",
    "    return adjList\n",
    "\n",
    "def addHopFeatures(features, adj, hop_count):\n",
    "    print('features_n_hop start')\n",
    "\n",
    "    numNodes = features.shape[0]\n",
    "\n",
    "    adjList = convert(numNodes, adj)\n",
    "\n",
    "    n_hop_neighbors = hop_count\n",
    "\n",
    "    Vertices_attributes_oneHot = pd.DataFrame.sparse.from_spmatrix(features)\n",
    "\n",
    "    all_nodes_distribution = np.zeros((numNodes, len(Vertices_attributes_oneHot.columns)))\n",
    "\n",
    "    for eachNode in range(numNodes):\n",
    "        Immediate_friends_Nodes = getNHopNeighbors(eachNode, n_hop_neighbors, adjList) # gets a list of adjacent nodes till n hop\n",
    "        Vertices_attributes_sum = Vertices_attributes_oneHot.iloc[list(Immediate_friends_Nodes)].sum()\n",
    "        Vertices_attributes_sum = Vertices_attributes_sum.to_numpy()\n",
    "        Vertices_attributes_sum[Vertices_attributes_sum > 0] = 1 # replace non-zero with 1\n",
    "        all_nodes_distribution[eachNode] = Vertices_attributes_sum\n",
    "\n",
    "    features_n_hop = sparse.csr_matrix(all_nodes_distribution) # convert to sparse matrix\n",
    "\n",
    "    with open('features_n_hop.pickle', 'wb') as handle: pickle.dump(features_n_hop, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    print('features_n_hop done')\n",
    "\n",
    "    return features_n_hop\n",
    "\n",
    "def addHopAdjacency(adj, hop_count):\n",
    "    print('adjacency_n_hop start')\n",
    "    print(\"---------------------\")\n",
    "\n",
    "    numNodes = adj.shape[0]           # 6271 for mmu\n",
    "    print('numNodes:', numNodes)\n",
    "\n",
    "    adjList = convert(numNodes, adj)\n",
    "\n",
    "    n_hop_neighbors = hop_count\n",
    "\n",
    "    nHopAdj = np.zeros((numNodes, numNodes), dtype=int)\n",
    "\n",
    "    for eachNode in range(numNodes):\n",
    "        Immediate_friends_Nodes = getNHopNeighbors(eachNode, n_hop_neighbors, adjList) # gets a list of adjacent nodes till n hop\n",
    "\n",
    "        for friends_Node in Immediate_friends_Nodes:\n",
    "            nHopAdj[eachNode][friends_Node] = 1\n",
    "\n",
    "    nHopAdj = sparse.csr_matrix(nHopAdj) # convert to sparse matrix\n",
    "\n",
    "    # with open('KEGG_pickles/adj_n_hop.pickle', 'wb') as handle: pickle.dump(nHopAdj, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    print('adj_n_hop done')\n",
    "\n",
    "    return nHopAdj\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a28999a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store(features, adj, hop_count):\n",
    "    # Manually store hopped info in pickle\n",
    "    features = addHopFeatures(features, adj, hop_count)\n",
    "    adj = sparse.csr_matrix(adj)\n",
    "    adj = addHopAdjacency(adj, hop_count + 1)\n",
    "\n",
    "    f1 = 'pickles/' + data_name + '_features_hop_' + str(hop_count) + '_stellergraph' + '.pickle'\n",
    "    a1 = 'pickles/' + data_name + '_adj_hop_' + str(hop_count) + '_stellergraph' + '.pickle'\n",
    "    with open(f1, 'wb') as handle: pickle.dump(features, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    with open(a1, 'wb') as handle: pickle.dump(adj, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4476fd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hop_count = [2]\n",
    "data_name = 'cora'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8ccd54b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_n_hop start\n",
      "features_n_hop done\n",
      "adjacency_n_hop start\n",
      "---------------------\n",
      "numNodes: 2485\n",
      "adj_n_hop done\n"
     ]
    }
   ],
   "source": [
    "for each in hop_count:\n",
    "    store(features, adj, each)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
